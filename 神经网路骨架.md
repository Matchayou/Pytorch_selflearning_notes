### torch.nn介绍（nn = neural network）
[[torch.nn — PyTorch 2.7 documentation](https://docs.pytorch.org/docs/stable/nn.html)]()

#### 代码笔记
![[nn.module_notes.ipynb]]
![[nn.conv2d_notes 1.ipynb]]
![[nn.maxpool2d_notes.ipynb]]
![[nn.non-linear_activations_notes.ipynb]]
![[nn.linear_notes.ipynb]]

## 卷积层
Module:模板，有默认定义，可以进行修改
```python
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        #以下是需要自己写的
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
```
  这段代码实现了一个两层卷积神经网络，每层卷积操作后都跟随一个 ReLU 激活函数。它的目的就是通过卷积操作提取输入数据（比如图像）中的特征，并通过非线性激活函数引入非线性关系，使模型能够学习复杂的模式。
### 补充知识：卷积
在卷积神经网络（CNN）中，卷积层的 **卷积核**（kernel）、**输入通道数**（input channels）和**输出通道数**（output channels）是三个重要的参数。它们的意义和相互关系如下：
#### 1. **卷积核（Kernel）**
- **含义**：卷积核是一个小的权重矩阵，用来在输入数据上滑动并进行卷积运算。它在图像中滑动，通过加权求和的方式提取局部特征，如边缘、角点等。对数据做出最优加权
- **决定因素**：卷积核的大小（如 `3x3`、`5x5`）决定了它在图像上滑动时覆盖的区域大小。通常，卷积核的大小是超参数，可以根据实际任务选择。卷积核的数量（即输出通道数）会影响模型提取的特征的数量和多样性。
- **经过多次训练后，网络会根据数据不断调整卷积核的值**
#### 2. **输入通道数（Input Channels）**
- **含义**：输入通道数指的是输入数据的通道数。例如，彩色图像有三个通道（RGB），灰度图像有一个通道。每个输入通道会与卷积核进行卷积运算，生成不同的特征图。
- **决定因素**：输入通道数通常由输入数据的特征决定。对于图像数据来说，灰度图像的输入通道数为 1，RGB 彩色图像的输入通道数为 3。对于多模态输入数据，通道数可能更高（例如，多个传感器数据）。
#### 3. **输出通道（Output Channels）**
- **含义**：输出通道数表示卷积层生成的特征图的数量。每个卷积核生成一个特征图，输出通道数即为卷积层生成特征图的数量。例如，输出通道数为 20 时，表示卷积层将生成 20 个特征图。
- **决定因素**：输出通道数由卷积层的设计决定。它决定了卷积层学习到多少不同类型的特征，通常根据任务的复杂度和网络的深度进行选择。
#### 总结：
- **卷积核**负责从输入中提取局部特征。
- **输入通道数**取决于输入数据的特性（如图像的颜色通道）。
- **输出通道数**决定了卷积层会学习多少个特征图，它由网络设计者决定，通常随着网络的深度增加而增大。
### 参数解读
in_channels:输入的通道数
out_channels：实质上是卷积核的数量
weight/kernel_size：卷积核的大小
stride：卷积核移动的步数
padding：对上下左右两边进行填充（一般为0）
bias：偏置，常年设置为True
padding_mode: 如何进行padding填充，一般为“zero”
### VGG16
![[Pasted image 20250730224828.png]]
图解：input_channel =3,output_channel = 64
卷积后的特征图和原始输入图像的高度和宽度并不是总是一样的，是由对应的公式决定的：
$$
H_{\text{out}} = \left\lfloor \frac{H_{\text{in}} + 2 \times \text{padding}[0] - \text{dilation}[0] \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1 \right\rfloor
$$
$$
W_{\text{out}} = \left\lfloor \frac{W_{\text{in}} + 2 \times \text{padding}[1] - \text{dilation}[1] \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1 \right\rfloor
$$
#### 卷积部分代码笔记
![[nn.conv2d_notes.ipynb]]

## 池化层<center></center>
池化（Pooling）是卷积神经网络（CNN）中用于下采样的操作，其目的是通过减少特征图的尺寸来降低计算量，同时保留图像中的重要信息。池化操作通常会使用一个滑动窗口，在输入的特征图上滑动，应用某种聚合方式（如最大值或平均值），从而生成缩小的输出特征图。
常见的池化操作：
- **最大池化（Max Pooling）**：在每个池化区域中，选择该区域内的最大值作为输出。
- **平均池化（Average Pooling）**：在每个池化区域中，计算该区域内所有值的平均值作为输出。
池化的操作通常包括两个重要的参数：
1. **池化窗口大小（Kernel Size）**：决定了池化操作的感受野，例如 `2x2` 或 `3x3`。
2. **步幅（Stride）**：决定了池化窗口每次滑动的距离。
通过池化，特征图的尺寸会缩小，计算量减少，同时保留了输入数据中最重要的局部特征，使网络更具平移不变性。
3. **执行池化操作**：
    
    - 在特征图上按步幅滑动池化窗口，覆盖每个区域。
        
    - 对每个覆盖的区域，根据池化类型进行聚合（取最大值或平均值）。
        
4. **生成输出**：池化操作会产生一个新的特征图，该特征图的尺寸相较于输入特征图通常会更小（例如：`2x2` 池化窗口可能将图像尺寸缩小一半）。
#### **示例**：
假设输入特征图是：
```css
[ [1, 3, 2, 4],
  [5, 6, 7, 8],
  [9, 10, 11, 12],
  [13, 14, 15, 16] ]
```
使用 `2x2` 的最大池化窗口，步幅为 2，池化过程如下：
- 第一个池化窗口：覆盖 `[1, 3, 5, 6]`，最大池化选择 6。
- 第二个池化窗口：覆盖 `[2, 4, 7, 8]`，最大池化选择 8。
- 以此类推，池化后的输出特征图为：
```css
[ [6, 8],
  [14, 16] ]
```
池化就像是在看一张非常复杂的地图。地图上有很多细节和小信息，但你只关心最重要的部分。池化就像是**使用放大镜**对地图上的一个小区域进行“精简”，把该区域最显眼的部分挑选出来，从而不需要查看每一个小细节。

### MaxPool2d
**stride**： – the stride of the window. Default value is `kernel_siz`
**dilation**：空洞卷积
**ceil_mode** ([_bool_](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")) – when True, will use ceil instead of floor to compute the output shape，取整的方法（矩阵边缘数字是否保留）
![[Pasted image 20250731142448.png]]
![[Pasted image 20250731142833.png]]
**鲁棒性**（Robustness）是指系统、模型或算法在面对不确定性、干扰、噪声或变化的情况下，依然能保持稳定、有效、可靠的性能的能力。
池化可以增强模型的鲁棒性，减少过拟合，减少数据量，加快训练

## 非线性激活
给网络引入非线性特征，使得网络被训练成符合各种曲线和特征的图形
如果没有非线性激活函数，那么即使网络层数非常深，所有层的组合仍然是线性函数。因此，神经网络无论层数多少，最终都只能逼近一个线性函数，无法有效地解决复杂的非线性问题。
### ReLu
![[Pasted image 20250731175737.png]]


inplace含义
在不在原来的位置直接进行替换（深浅拷贝，是否会影响原始对象）

```python
input = -1
Relu(input,inplace = True)
Input = 0
```
```
input = -1
Output = Relu(input,inplace = False)
Input = -1
Output = 0
```

## 神经网路线性层
torch.flatten()：将数据展平
### 3. 为什么需要展平（Flatten）？
在一些情况下，可能需要将图像数据展平（flatten）为一个一维向量，而不是保持为多维的图像形式。这通常发生在以下几种情况：
- **全连接层（Fully Connected Layer）**：全连接层接受的输入是一个一维向量。为了将卷积层或池化层的输出传递到全连接层，通常需要展平图像数据。例如，卷积层输出的是 `(batch_size, channels, height, width)`，需要展平成 `(batch_size, channels*height*width)`。
- **数据预处理**：某些任务要求对输入数据进行预处理，比如将其变换为一维向量形式以便后续的操作。
```python
output = torch.reshape(imgs,(1,1,1,-1))
# Reshape to (1, 1, 1, 64*3*32*32)
#把图片展平为一维向量
output = torch.flatten(imgs)
#把输入展平为一维向量
```
都展平，但是torch.flatten会保留批次信息
